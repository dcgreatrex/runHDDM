{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import hddm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os as os\n",
    "%pylab inline\n",
    "from pylab import *\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "main_folder = '.../hddm_example'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Tests all combinations of letting v, a, t_er vary by periodicity condition.\n",
    "# Allows v, vary across difficulty condition.\n",
    "# Group level estimate of trial by trial variability.\n",
    "# z is calcualted for each P.       \n",
    "def run_model_set(id):\n",
    "    \n",
    "    # packages\n",
    "    import hddm\n",
    "    # define folders & load data\n",
    "    data_folder = [main_folder + \"hddm_data/\"]\n",
    "    trace_folder = '/model_trace'\n",
    "    filename = \"hddm_stim_coding.csv\"\n",
    "    data = hddm.load_csv(data_folder + filename)\n",
    "    # set sampling criteria\n",
    "    no_samples = 15000\n",
    "    burn_in = 5000\n",
    "    \n",
    "    # run parallel processes\n",
    "    if id == 0: \n",
    "        print('running model %i'%id);\n",
    "        m = hddm.HDDM(data, include=('z', 'sv', 'st', 'sz'), group_only_nodes=['sv', 'st', 'sz'], \n",
    "                  depends_on={'a': ['periodicity'], 'v': ['level']}, p_outlier=0.05)\n",
    "        m.find_starting_values()\n",
    "        m.sample(no_samples, burn=burn_in, dbname=main_folder + trace_folder + '/db%i'%id, db='pickle')\n",
    "        m.save(main_folder + trace_folder + '/set_m%i%i'%id)\n",
    "        return m\n",
    "    \n",
    "    if id == 1:\n",
    "        print('running model %i'%id);\n",
    "        m = hddm.HDDM(data, include=('z', 'sv', 'st', 'sz'), group_only_nodes=['sv', 'st', 'sz'], \n",
    "                  depends_on={'v': ['periodicity', 'level']}, p_outlier=0.05)\n",
    "        m.find_starting_values()\n",
    "        m.sample(no_samples, burn=burn_in, dbname=main_folder + trace_folder + '/db%i'%id, db='pickle')\n",
    "        m.save(main_folder + trace_folder + '/set_m%i%i'%id)\n",
    "        return m \n",
    "        \n",
    "    if id == 2:\n",
    "        print('running model %i'%id);\n",
    "        m = hddm.HDDM(data, include=('z', 'sv', 'st', 'sz'), group_only_nodes=['sv', 'st', 'sz'], \n",
    "                  depends_on={'v': ['level'], 't': ['periodicity']}, p_outlier=0.05)\n",
    "        m.find_starting_values()\n",
    "        m.sample(no_samples, burn=burn_in, dbname=main_folder + trace_folder + '/db%i'%id, db='pickle')\n",
    "        m.save(main_folder + trace_folder + '/set_m%i%i'%id)\n",
    "        return m  \n",
    "\n",
    "    if id == 3:\n",
    "        print('running model %i'%id);\n",
    "        m = hddm.HDDM(data, include=('z', 'sv', 'st', 'sz'), group_only_nodes=['sv', 'st', 'sz'], \n",
    "                  depends_on={'v': ['periodicity', 'level'], 't': ['periodicity']}, p_outlier=0.05)\n",
    "        m.find_starting_values()\n",
    "        m.sample(no_samples, burn=burn_in, dbname=main_folder + trace_folder + '/db%i'%id, db='pickle')\n",
    "        m.save(main_folder + trace_folder + '/set_m%i%i'%id)      \n",
    "        return m \n",
    "\n",
    "    if id == 4:\n",
    "        print('running model %i'%id);\n",
    "        m = hddm.HDDM(data, include=('z', 'sv', 'st', 'sz'), group_only_nodes=['sv', 'st', 'sz'], \n",
    "                  depends_on={'a': ['periodicity'], 'v': ['level'], 't': ['periodicity']}, p_outlier=0.05)\n",
    "        m.find_starting_values()\n",
    "        m.sample(no_samples, burn=burn_in, dbname=main_folder + trace_folder + '/db%i'%id, db='pickle')\n",
    "        m.save(main_folder + trace_folder + '/set_m%i%i'%id)  \n",
    "        return m \n",
    "      \n",
    "    if id == 5:\n",
    "        print('running model %i'%id);\n",
    "        m = hddm.HDDM(data, include=('z', 'sv', 'st', 'sz'), group_only_nodes=['sv', 'st', 'sz'], \n",
    "                  depends_on={'a': ['periodicity'], 'v': ['periodicity', 'level']}, p_outlier=0.05)\n",
    "        m.find_starting_values()\n",
    "        m.sample(no_samples, burn=burn_in, dbname=main_folder + trace_folder + '/db%i'%id, db='pickle')\n",
    "        m.save(main_folder + trace_folder + '/set_m%i%i'%id)   \n",
    "        return m  \n",
    "        \n",
    "    if id == 6: \n",
    "        print('running model %i'%id);\n",
    "        m = hddm.HDDM(data, include=('z', 'sv', 'st', 'sz'), group_only_nodes=['sv', 'st', 'sz'], \n",
    "                  depends_on={'a': ['periodicity'], 'v': ['periodicity', 'level'], 't': ['periodicity']}, p_outlier=0.05)\n",
    "        m.find_starting_values()\n",
    "        m.sample(no_samples, burn=burn_in, dbname=main_folder + trace_folder + '/db%i'%id, db='pickle')\n",
    "        m.save(main_folder + trace_folder + '/set_m%i%i'%id)   \n",
    "        return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#----------------------\n",
    "# RUN MODEL SET 1\n",
    "#----------------------\n",
    "# start 7 CPU clusters in background - enter into new terminal.\n",
    "# ipcluster start -n 7\n",
    "\n",
    "# run model set 1\n",
    "from IPython.parallel import Client\n",
    "v = Client()[:]\n",
    "jobs = v.map(run_model_set, range(7)) # 7 is the number of live CPUs required\n",
    "m_set = jobs.get()\n",
    "\n",
    "# stop 7 CPU clusters in background - enter into new terminal.\n",
    "# ipcluster stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#----------------------\n",
    "# Load models from file\n",
    "#----------------------\n",
    "model_1 = hddm.load(main_folder + trace_folder + '/set_m0')\n",
    "model_2 = hddm.load(main_folder + trace_folder + '/set_m1')\n",
    "model_3 = hddm.load(main_folder + trace_folder + '/set_m2')\n",
    "model_4 = hddm.load(main_folder + trace_folder + '/set_m3')\n",
    "model_5 = hddm.load(main_folder + trace_folder + '/set_m4')\n",
    "model_6 = hddm.load(main_folder + trace_folder + '/set_m5')\n",
    "model_7 = hddm.load(main_folder + trace_folder + '/set_m6')\n",
    "model_list = [model_1,model_2,model_3,model_4,model_5,model_6,model_7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#----------------------\n",
    "# Extract ordered DIC values to .csv file\n",
    "#----------------------\n",
    "dic_folder = '/DIC'\n",
    "dic_array = []\n",
    "for i in range(0,len(model_list)):\n",
    "    dic_array.append(model_list[i].dic)\n",
    "model_id = list(range(1,len(model_list)+1))\n",
    "dic_table = pd.DataFrame({'model_id' : model_id,'DIC' : dic_array})\n",
    "# sort tables by values\n",
    "dic_table = dic_table.sort_values(by = ['DIC'])\n",
    "# save to file\n",
    "dic_table.to_csv(main_folder + dic_folder + '/diffusion_set_DIC.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#----------------------\n",
    "# Extract model statistics and save to .csv file\n",
    "#----------------------\n",
    "statistics_folder = '/statistics'\n",
    "for i in range(0,len(model_list)):\n",
    "    stats = model_list[i].gen_stats()\n",
    "    filename = main_folder + statistics_folder + '/model_' + str(i+1) + '/model_' + str(i+1) + '_stats.csv'\n",
    "    os.makedirs(os.path.dirname(filename))\n",
    "    stats.to_csv(filename, index=True, index_label='Parameter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#----------------------\n",
    "# Save posterior plots to file for each model\n",
    "#----------------------\n",
    "plots_folder = '/statistics'\n",
    "pwd = os.getcwd()\n",
    "for i in range(0,len(model_list)):\n",
    "    filename =  main_folder + plots_folder + '/model_' + str(i+1) + '/'\n",
    "    os.makedirs(os.path.dirname(filename))\n",
    "    os.chdir(filename)\n",
    "    model_list[i].plot_posteriors(save=True)\n",
    "    plt.clf()\n",
    "    print('finished plotting posterior plots for model ' + str(i+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#----------------------\n",
    "# Test whether the models have convered using the Geweke statistic\n",
    "# You can also use the R-hat statistic (Gelman-Rubin) described here: http://ski.clps.brown.edu/hddm_docs/howto.html\n",
    "#----------------------\n",
    "from kabuki.analyze import check_geweke\n",
    "for i in range(0,len(model_list)):\n",
    "    print '-' * 30\n",
    "    print check_geweke(model_list[i],assert_=False)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#----------------------\n",
    "# Select one of the models for comparing parameter estimates: Pick the full model for demonstration.\n",
    "#----------------------\n",
    "tmp = model_list[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#----------------------\n",
    "# Plot boundary conditions\n",
    "#----------------------\n",
    "a_AP, a_P = tmp.nodes_db.node[['a(Aperiodic)', 'a(Periodic)']]\n",
    "hddm.analyze.plot_posterior_nodes([a_AP, a_P])\n",
    "plt.xlabel('Boundary condition')\n",
    "plt.ylabel('Posterior probability')\n",
    "plt.title('Posterior of boundary condition group means')\n",
    "#plt.savefig('hddm_demo_fig_06.pdf')\n",
    "print \"P(AP > P) = \", (a_AP.trace() > a_P.trace()).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#----------------------\n",
    "# Plot drift rate conditions\n",
    "#----------------------\n",
    "APvneg4,Pvneg4 = tmp.nodes_db.node[['v(-4.Aperiodic)','v(-4.Periodic)']]\n",
    "hddm.analyze.plot_posterior_nodes([APvneg4,Pvneg4])\n",
    "plt.xlabel('Drift rate condition')\n",
    "plt.ylabel('Posterior probability')\n",
    "plt.title('Posterior of drift rate group means')\n",
    "print \"Neg 4 - P(AP > P) = \", (APvneg4.trace() > Pvneg4.trace()).mean()\n",
    "\n",
    "APvneg2,Pvneg2 = tmp.nodes_db.node[['v(-2.Aperiodic)','v(-2.Periodic)']]\n",
    "hddm.analyze.plot_posterior_nodes([APvneg2,Pvneg2])\n",
    "plt.xlabel('Drift rate condition')\n",
    "plt.ylabel('Posterior probability')\n",
    "plt.title('Posterior of drift rate group means')\n",
    "print \"Neg 2 - P(AP > P) = \", (APvneg2.trace() > Pvneg2.trace()).mean()\n",
    "\n",
    "APvneg1,Pvneg1 = tmp.nodes_db.node[['v(-1.Aperiodic)','v(-1.Periodic)']]\n",
    "hddm.analyze.plot_posterior_nodes([APvneg1,Pvneg1])\n",
    "plt.xlabel('Drift rate condition')\n",
    "plt.ylabel('Posterior probability')\n",
    "plt.title('Posterior of drift rate group means')\n",
    "print \"Neg 1 - P(AP > P) = \", (APvneg1.trace() > Pvneg1.trace()).mean()\n",
    "\n",
    "APv0,Pv0 = tmp.nodes_db.node[['v(0.Aperiodic)','v(0.Periodic)']]\n",
    "hddm.analyze.plot_posterior_nodes([APv0,Pv0])\n",
    "plt.xlabel('Drift rate condition')\n",
    "plt.ylabel('Posterior probability')\n",
    "plt.title('Posterior of drift rate group means')\n",
    "print \"Zero - P(AP > P) = \", (APv0.trace() > Pv0.trace()).mean()\n",
    "\n",
    "APv1,Pv1 = tmp.nodes_db.node[['v(1.Aperiodic)','v(1.Periodic)']]\n",
    "hddm.analyze.plot_posterior_nodes([APv1,Pv1])\n",
    "plt.xlabel('Drift rate condition')\n",
    "plt.ylabel('Posterior probability')\n",
    "plt.title('Posterior of drift rate group means')\n",
    "print \"1 - P(AP > P) = \", (APv1.trace() > Pv1.trace()).mean()\n",
    "\n",
    "APv2,Pv2 = tmp.nodes_db.node[['v(2.Aperiodic)','v(2.Periodic)']]\n",
    "hddm.analyze.plot_posterior_nodes([APvneg4,Pvneg4])\n",
    "plt.xlabel('Drift rate condition')\n",
    "plt.ylabel('Posterior probability')\n",
    "plt.title('Posterior of drift rate group means')\n",
    "print \"2 - P(AP > P) = \", (APv2.trace() > Pv2.trace()).mean()\n",
    "\n",
    "APv4,Pv4 = tmp.nodes_db.node[['v(4.Aperiodic)','v(4.Periodic)']]\n",
    "hddm.analyze.plot_posterior_nodes([APv4,Pv4])\n",
    "plt.xlabel('Drift rate condition')\n",
    "plt.ylabel('Posterior probability')\n",
    "plt.title('Posterior of drift rate group means')\n",
    "print \"4 - P(AP > P) = \", (APv4.trace() > Pv4.trace()).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#----------------------\n",
    "# Plot non-decision time\n",
    "#----------------------\n",
    "t_AP, t_P = tmp.nodes_db.node[['t(Aperiodic)', 't(Periodic)']]\n",
    "hddm.analyze.plot_posterior_nodes([t_AP, t_P])\n",
    "plt.xlabel('Non-decision time condition')\n",
    "plt.ylabel('Posterior probability')\n",
    "plt.title('Posterior of non-decision time condition group means')\n",
    "#plt.savefig('hddm_demo_fig_06.pdf')\n",
    "print \"P(AP > P) = \", (t_AP.trace() > t_P.trace()).mean()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py27]",
   "language": "python",
   "name": "conda-env-py27-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
